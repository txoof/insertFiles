{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook insert_files.ipynb to python\n",
      "[NbConvertApp] Writing 42002 bytes to insert_files.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter-nbconvert --to python --template python_clean insert_files.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "\n",
    "# I'm not sure why this is needed, but this resolves a runtime crash when run from the command line\n",
    "# reassign the builtins.print function to bprint\n",
    "bprint = builtins.print\n",
    "\n",
    "try:\n",
    "    from . import constants\n",
    "except ImportError:\n",
    "    import constants\n",
    "\n",
    "try:\n",
    "    from . import error_msgs\n",
    "except ImportError:\n",
    "    import error_msgs\n",
    "\n",
    "try:\n",
    "    from .filestream import GoogleDrivePath, GDStudentPath\n",
    "except ImportError:\n",
    "    from filestream import GoogleDrivePath, GDStudentPath\n",
    "    \n",
    "import logging\n",
    "from logging import handlers\n",
    "from logging import config\n",
    "\n",
    "logging.config.fileConfig(constants.LOGGING_CONFIG, defaults={'logfile': constants.LOG_FILE} )\n",
    "\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import textwrap\n",
    "from datetime import datetime\n",
    "import re\n",
    "import subprocess\n",
    "import shlex\n",
    "import shutil\n",
    "# trailing slash -- os agnostic\n",
    "from os import sep\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PySimpleGUI as sg\n",
    "import ArgConfigParse\n",
    "from tinydb import TinyDB, Query\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORMAT = constants.FORMAT\n",
    "# DATEFMT = constants.DATEFMT\n",
    "# logging.basicConfig(format=FORMAT, datefmt=DATEFMT,\n",
    "#                     level=logging.DEBUG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_exit(e='unknown error in unknown module!', exit_status=99):\n",
    "    '''handle exits and return exit function with either a soft_exit or hard_exit -\n",
    "        The returned function can be executed by the calling process when it is ready \n",
    "        rather than forcing an exit immediately \n",
    "    \n",
    "        soft_exit prints message and optionally logs message\n",
    "        hard_exit prints message, logs and calls sys.exit(exit_status)\n",
    "    \n",
    "    Args:\n",
    "        e(`str`): error or message detailing reason for exiting\n",
    "        exit_status(int): exit value --\n",
    "            0: soft_exit with no logging -- normal exit with no issues\n",
    "            1: soft_exit with logging -- exit due to recoverable issue\n",
    "            >1: hard_exit with logging -- abort execution with sys.exit(exit_status)\n",
    "            \n",
    "    Returns:\n",
    "        function: soft_exit, hard_exit'''\n",
    "    help_msg = f'try:\\n{sys.argv[0]} -h for help'\n",
    "    def hard_exit():\n",
    "        print(e)\n",
    "        sys.exit(exit_status)\n",
    "        \n",
    "    def soft_exit():\n",
    "        print(e)\n",
    "        return(e)\n",
    "    \n",
    "    if exit_status > 1:\n",
    "        logging.error(f'fatal error:\\n\\t{e}')\n",
    "        return(hard_exit)\n",
    "    \n",
    "    if exit_status == 1:\n",
    "        logging.warning(f'exited before completion with code {exit_status}')\n",
    "        logging.warning(e)\n",
    "        print(help_msg)\n",
    "        return(soft_exit)\n",
    "    \n",
    "    if exit_status < 1:\n",
    "        logging.debug(e)\n",
    "        return(soft_exit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_handler(handler=None, new_level=None):\n",
    "    '''adjust a logging handler\n",
    "    \n",
    "    Args:\n",
    "        handler(`str`): partial string in handler name - if none, returns list of all handlers attached to root\n",
    "            '*' adjusts all handlers to new_level\n",
    "        new_level(`str`): DEBUG, INFO, WARNING, ERROR\n",
    "    \n",
    "    Returns:\n",
    "        `list`: list of handlers and levels currently set'''\n",
    "    if not handler:\n",
    "        return(logging.getLogger().handlers)\n",
    "    \n",
    "    my_handler = None    \n",
    "    for index, val in enumerate(logging.getLogger().handlers):\n",
    "        if handler == '*':\n",
    "            my_handler = logging.getLogger().handlers[index]\n",
    "        else:\n",
    "            if handler in str(val):\n",
    "                my_handler = logging.getLogger().handlers[index]\n",
    "        if my_handler:\n",
    "            logging.info(f'setting {str(my_handler)} to {new_level}')\n",
    "            my_handler.setLevel(new_level)\n",
    "        else:\n",
    "            logging.warning(f'handler: \"{handler}\" not found')\n",
    "        \n",
    "    return logging.getLogger().handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_line_string():\n",
    "    '''multi-line string object \n",
    "    \n",
    "    each time  multi_line_string.string is set equal to a string, it is added to \n",
    "    the existing string with a new line character\n",
    "    \n",
    "    Properties:\n",
    "        string(`str`): string'''\n",
    "\n",
    "    def __init__(self, s=''):\n",
    "        self._string = ''\n",
    "        self.append(s)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.string)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return(str(self.string))\n",
    "    \n",
    "    @property\n",
    "    def string(self):\n",
    "        return self._string\n",
    "    \n",
    "    @string.setter\n",
    "    def string(self, s):\n",
    "        self._string = s\n",
    "    \n",
    "    def append(self, s):\n",
    "        self._string = self._string + s + '\\n'\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_print(t='', width=None, supress_print=False):\n",
    "    '''print a text-wrapped string\n",
    "    \n",
    "    Args:\n",
    "        t(`str`): text to wrap\n",
    "        width(`int`): characters to wrap -- defaults to constants.TEXT_WIDTH\n",
    "        \n",
    "    Returns:\n",
    "        str'''\n",
    "    if not width:\n",
    "        width = constants.TEXT_WIDTH\n",
    "        \n",
    "    wrapper = textwrap.TextWrapper(width=width, break_long_words=False, replace_whitespace=False)\n",
    "    result = '\\n'.join([wrapper.fill(line) for line in t.splitlines()])\n",
    "# this causes a runtime crash; it's unclear why, but is resolved by reassigning bprint = builtins.print \n",
    "#     builtins.print(result)\n",
    "    if not supress_print:\n",
    "        bprint(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cmdargs():\n",
    "    args = ArgConfigParse.CmdArgs()\n",
    "    \n",
    "    args.add_argument('-i', '--insert_source', ignore_none=True, \n",
    "                      metavar='/path/to/student/records/',\n",
    "                      type=str, dest='insert_source', help='Full path to file to be inserted')\n",
    "    \n",
    "    args.add_argument('-g', '--google_drive', ignore_none=True, \n",
    "                      metavar='/Volumes/GoogleDrive/Shared drives/ASH Cum Folders/folder/',\n",
    "                      type=str, dest='main__drive_path', help='Full path to Google Drive Shared Drive containing cumulative files')\n",
    "\n",
    "    args.add_argument('-l', '--log_level', ignore_none=True, metavar='ERROR, WARNING, INFO, DEBUG', \n",
    "                      type=str, dest='main__log_level', help='Logging level -- Default: WARNING')\n",
    "    args.add_argument('-v', '--version', dest='version', action='store_true',\n",
    "                      default=False, help='Print version number and exit')\n",
    "    \n",
    "    args.add_argument('-u', '--update_drive', action='store_true',\n",
    "                       default=False, dest ='update_drive', help='Update config file with supplyed -g option')\n",
    "    \n",
    "    args.add_argument('--more_help', dest='more_help', action='store_true',\n",
    "                       default=False, help='Print extened help and exit')\n",
    "\n",
    "\n",
    "    args.parse_args()\n",
    "    return args.nested_opts_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(files):\n",
    "    '''parse .ini files \n",
    "    \n",
    "    Args:\n",
    "        files(`list`): list of `str` containing files in .ini format to parse\n",
    "    \n",
    "    Returns:\n",
    "        `dict`: nested dict of configuration'''\n",
    "    parser = ArgConfigParse.ConfigFile(config_files=files, ignore_missing=True)\n",
    "    parser.parse_config()\n",
    "    \n",
    "    return parser.config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_drive_path(drive_path=None):\n",
    "    '''check that path is a valid google drive path and contains the appropriate sentry file\n",
    "    \n",
    "    Args:\n",
    "        drive_path(`str`): path to google drive containg cummulative folders and sentry file\n",
    "    \n",
    "    Retruns:\n",
    "        `tuple` of `bool`, `str`: When true, drive is OK; when false, drive is not valid; str contains errors'''\n",
    "    # this is super redundant -- checks the following:\n",
    "    # * is a path\n",
    "    # * is a google drive path\n",
    "    # * if sentry file exists\n",
    "    # this may be a good idea considering how some users have run into many problems with this\n",
    "    SENTRY_FILE = constants.SENTRY_FILE    \n",
    "    sentry_file_path = drive_path/Path(SENTRY_FILE)\n",
    "    drive_ok = True\n",
    "    msg = None\n",
    "    \n",
    "    if not drive_path:\n",
    "        logging.info('no google drive specified')\n",
    "        drive_ok = False\n",
    "        msg = 'No Google Drive specified'\n",
    "        return drive_ok, msg\n",
    "    else:\n",
    "        drive_path = Path(drive_path)\n",
    "    \n",
    "    if not drive_path.exists():\n",
    "        logging.warning(f'specified path \"{drive_path}\" does not exist')\n",
    "        drive_ok = False\n",
    "#         msg = f'The Google Drive \"{drive_path}\" does not appear to exist on Google Drive'\n",
    "        msg = error_msgs.PATH_ERROR.format(drive_path=drive_path)\n",
    "        return drive_ok, msg\n",
    "    else:\n",
    "        google_drive = GoogleDrivePath(drive_path)\n",
    "    \n",
    "    try:\n",
    "        google_drive.get_xattr('user.drive.id')\n",
    "    except ChildProcessError as e:\n",
    "        logging.warning(f'specified path \"{drive_path}\" is not a Google Drive path')\n",
    "#         msg = f'The Google Drive \"{drive_path}\" does not appear to be a valid google Shared Drive'\n",
    "        msg = error_msgs.NON_GDRIVE_ERROR.format(drive_path=drive_path)\n",
    "        drive_ok = False\n",
    "        return drive_ok, msg\n",
    "\n",
    " \n",
    "    if not sentry_file_path.is_file():\n",
    "        logging.warning(f'sentry file is missing in specified path \"{drive_path}\"')\n",
    "        msg = error_msgs.SENTRY_ERROR.format(drive_path=drive_path, sentry_file=SENTRY_FILE, sentry_file_path=sentry_file_path)\n",
    "        drive_ok = False\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    return drive_ok, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_help():\n",
    "    logging.debug('getting help')\n",
    "    console = Console()\n",
    "    console.options.max_width = constants.TEXT_WIDTH\n",
    "    try:\n",
    "        with open(constants.HELP_FILE) as help_file:\n",
    "            markdown = Markdown(help_file.read())\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return do_exit(f'Error getting help!\\n{e}', 1)\n",
    "    \n",
    "    console.print(markdown)\n",
    "    return do_exit(' ', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_db():\n",
    "    db_file = Path(constants.STORAGE/constants.DATABASE)\n",
    "    \n",
    "    if not db_file.parent.exists():\n",
    "        try:\n",
    "            db_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        except Exception as e:\n",
    "            logging.error(f'failed to create DB Directory -- fatal error: {e}')\n",
    "            db = None\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        db = TinyDB(db_file)\n",
    "    except Exception as e:\n",
    "        logging.error(f'failed to open DB File: {e}')\n",
    "        db = None\n",
    "        \n",
    "    \n",
    "    return db    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class job_time():\n",
    "    def __init__(self):\n",
    "        self.job_id = int(time.time())\n",
    "        \n",
    "    def date_time(self, job=None):\n",
    "        if not job:\n",
    "            job = self.job_id\n",
    "        return(time.ctime(job))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def window_get_dir():\n",
    "#     file_list = None\n",
    "#     glob_path = sg.popup_get_folder('Choose a folder containing files to insert into Google Shared Drive',\n",
    "#                                    title='Choose a folder',\n",
    "#                                    initial_folder = '~/',\n",
    "#                                    keep_on_top=True,\n",
    "#                                    font=constants.FONT,\n",
    "#                                    location=constants.POPUP_LOCATION)\n",
    "    \n",
    "#     if glob_path:\n",
    "#         file_list = [f for f in Path(glob_path).glob('*')]\n",
    "#     else:\n",
    "#         logging.info('no folder selected by user')\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "#     return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_drive_path():\n",
    "    '''sg window that prompts to pick a google drive folder'''\n",
    "    drive_path = sg.popup_get_folder('Choose the Google Shared Drive **AND** folder that contains student cumulative folders.', \n",
    "                                     title='Select A Shared Drive', \n",
    "                                     initial_folder='/Volumes/GoogleDrive/',\n",
    "                                     keep_on_top=True, font=constants.FONT, \n",
    "                                     location=constants.POPUP_LOCATION)\n",
    "    if drive_path:\n",
    "        drive_path=Path(drive_path)\n",
    "        logging.debug(f'user selected: {drive_path}')\n",
    "    else:\n",
    "        drive_path = None\n",
    "        logging.info('no drive path selected by user')\n",
    "    return drive_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_get_dir():\n",
    "    '''sg window that prompts for a folder\n",
    "    \n",
    "    Returns:\n",
    "        (event(`str`), file_list(`list`)): tuple of window read event, list of selected files or None'''\n",
    "    file_list = None\n",
    "    layout = [ [sg.Text('Choose a folder containing files to insert into Cumulative Folders',\n",
    "                        font=f'{constants.FONT_FACE} {constants.FONT_SIZE+2}')],\n",
    "               [sg.Text(wrap_print(f'{constants.APP_NAME} will insert the selected files into a Cumulative Folders'), font=constants.FONT)],\n",
    "               [sg.Input(key='-INSERT-', font=constants.FONT), sg.FolderBrowse(font=constants.FONT, target='-INSERT-')],\n",
    "               [sg.Button('OK', font=constants.FONT), sg.Button('Cancel', font=constants.FONT), ]\n",
    "             ]\n",
    "    \n",
    "    window = sg.Window('Choose a Folder', layout, keep_on_top=True, location=constants.POPUP_LOCATION)\n",
    "    \n",
    "    while True:\n",
    "        event, values = window.read()\n",
    "        \n",
    "        if event in (sg.WIN_CLOSED, 'Cancel'):\n",
    "            event = 'Cancel'\n",
    "            break\n",
    "        if event == 'OK':\n",
    "            break\n",
    "            \n",
    "    if values['-INSERT-']:\n",
    "        file_list = [f for f in Path(values['-INSERT-']).glob('*')]\n",
    "    \n",
    "    window.Close()\n",
    "    return event, file_list\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grade_level():\n",
    "    '''sg window that prompts for a slection from constants.STUDENT_DIRS\n",
    "    \n",
    "    Returns:\n",
    "        `str`: selected list item'''\n",
    "    grade_level = None\n",
    "    width = 45\n",
    "    layout = [ [sg.Text('Choose A Grade Level', font=constants.FONT)],\n",
    "               [sg.Text(wrap_print(f'{constants.APP_NAME} will insert the chosen files into this grade-level folder for each student', width, True), \n",
    "                                  font=f'{constants.FONT_FACE} {constants.FONT_SIZE-2}')],\n",
    "               [sg.Listbox(values=constants.STUDENT_DIRS, font=constants.FONT, size=(width-15, len(constants.STUDENT_DIRS)), key='-LIST-', enable_events=True)],\n",
    "               [sg.Button('OK'), sg.Button('Cancel')]\n",
    "             ]\n",
    "    window = sg.Window('Choose a Grade Level', layout, keep_on_top=True, location=constants.POPUP_LOCATION)\n",
    "    \n",
    "    while True:\n",
    "        event, values = window.read()\n",
    "        logging.debug(f'user slected: {values}')\n",
    "        \n",
    "        if event in (sg.WIN_CLOSED, 'Cancel'):\n",
    "            break\n",
    "        if event == 'OK':\n",
    "            grade_level = values['-LIST-'][0]\n",
    "            break\n",
    "    window.close()\n",
    "    return event, grade_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_jobs(show_deleted=False):\n",
    "    '''return list of jobs stored in database\n",
    "    Args:\n",
    "        None\n",
    "    \n",
    "    Returns:\n",
    "        `list` of `dict` [{'Mon Day Year - H:M:S': job_id}]'''\n",
    "#     try:\n",
    "#         db = TinyDB(constants.DATABASE_PATH)\n",
    "#     except (OSError) as e:\n",
    "#         logging.error(f'failed to open database {constants.DATABASE_PATH}: {e}')\n",
    "#         return False\n",
    "    db = init_db()\n",
    "    \n",
    "    if not db:\n",
    "        job_list = []\n",
    "        logging.warning('failed to read jobs from DB -- See previous errors')\n",
    "    else:\n",
    "        job_set = set()\n",
    "        job_list = {}\n",
    "        format = \"%b %d %Y - %H:%M:%S\"\n",
    "        [job_set.add(i['job_id']) for i in db.search((Query().job_id.exists())  ) ]\n",
    "\n",
    "\n",
    "        for job_id in job_set:\n",
    "            job_summary = {}\n",
    "            date = datetime.fromtimestamp(job_id).strftime(format)\n",
    "            result = db.search((Query().job_id == job_id) & (Query().deleted == show_deleted))\n",
    "\n",
    "            location = f\"{result[0]['sub_folder']} folder\" if not result[0]['sub_folder'] == None else 'No valid files remain'\n",
    "            title = f'{date}: {len(result)} files --> {location}'\n",
    "            job_list[title] = job_id\n",
    "    #     [job_list.update({datetime.fromtimestamp(i).strftime(format) :i}) for i in job_set]\n",
    "\n",
    "    \n",
    "    return job_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_get_past_job():\n",
    "    '''sg window that prompts user to select previously run job id\n",
    "    \n",
    "    Returns:\n",
    "        event, `int`: job_id from database'''\n",
    "    \n",
    "    logging.debug('prompt user to select past job id for deletion')\n",
    "    job_id = None\n",
    "    job_list = list_jobs()\n",
    "    values=sorted(job_list.keys())\n",
    "    if len(job_list) < 1:\n",
    "        job_list.append({'No previous jobs found': None})\n",
    "\n",
    "    width = 50\n",
    "    for j in job_list:\n",
    "        if len(j) + 20 > width:\n",
    "            width = len(j)+20\n",
    "    height = 10\n",
    "    layout = [ [sg.Text('Choose A Past Job to Delete', font=constants.FONT)],\n",
    "               [sg.Text(wrap_print(f'{constants.APP_NAME} will attempt to permenently remove files inserted on a previous job', width, True), \n",
    "                                  font=f'{constants.FONT_FACE} {constants.FONT_SIZE-2}')],\n",
    "               [sg.Text(wrap_print(f'Past jobs are listed by date, number of files inserted and grade-level folder chosen', width, True), \n",
    "                                  font=f'{constants.FONT_FACE} {constants.FONT_SIZE-2}')],              \n",
    "               [sg.Listbox(values=values, font=constants.FONT, size=(width-15, height), key='-LIST-', enable_events=True, )],\n",
    "               [sg.Button('OK'), sg.Button('Cancel')]\n",
    "             ]\n",
    "    window = sg.Window('Choose a Previous Job', layout, keep_on_top=True, location=constants.POPUP_LOCATION)\n",
    "    \n",
    "    while True:\n",
    "        event, values = window.read()\n",
    "        logging.debug(f'user slected: {values}')\n",
    "        \n",
    "        if event in (sg.WIN_CLOSED, 'Cancel'):\n",
    "            logging.info('user canceled')\n",
    "            break\n",
    "        if event == 'OK':\n",
    "            try:\n",
    "                job_id = job_list[values['-LIST-'][0]]\n",
    "            except KeyError as e:\n",
    "                logging.error(f'error fetching job_id with key: {values[\"-LIST-\"][0]}: {e}')\n",
    "                job_id = None\n",
    "            except IndexError:\n",
    "                logging.info('user did not select a job')\n",
    "                job_id = None\n",
    "            break\n",
    "    window.close()\n",
    "    return event, job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def open_db():\n",
    "#     try:\n",
    "#         db = TinyDB(constants.DATABASE_PATH)\n",
    "#     except Exception as e:\n",
    "#         logging.error(f'error opening database: {constants.DATABASE_PATH}: {e}')\n",
    "#         db = None\n",
    "#     return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_cleanup(retire_age=None):\n",
    "    '''remove db entries older than retire_age\n",
    "    \n",
    "    Args:\n",
    "        retire_age(`int`): time in seconds \n",
    "        \n",
    "    Returns:\n",
    "        set(): doc ids deleted'''\n",
    "    \n",
    "    logging.debug(f'removing db entries older than {retire_age}')\n",
    "    db = init_db()\n",
    "    \n",
    "    if not db:\n",
    "        logging.error('could not read database -- see previous errors')\n",
    "        del_queue = set()\n",
    "    else:\n",
    "        if not retire_age:\n",
    "            retire_age = constants.RETIRE_AGE\n",
    "\n",
    "        if not isinstance(retire_age, (int, float)):\n",
    "            raise TypeError \n",
    "\n",
    "        del_queue = set()\n",
    "        now = int(time.time())\n",
    "\n",
    "        try:\n",
    "            old_items = db.search(Query().job_id < now - retire_age)\n",
    "        except (AttributeError ) as e:\n",
    "            logging.error(f'error opening database: {e}')\n",
    "            return []\n",
    "\n",
    "\n",
    "            [del_queue.add(i.doc_id) for i in old_items]\n",
    "\n",
    "\n",
    "        try:\n",
    "            db.remove(doc_ids=del_queue)\n",
    "        except KeyError as e:\n",
    "            logging.error(f'error removing documents {del_queue}: {e}')\n",
    "            return []\n",
    "\n",
    "        logging.info(f'removed {len(del_queue)} db entries')\n",
    "    return del_queue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_files():\n",
    "    logging.debug('prompt user to delete files')\n",
    "    db = init_db()\n",
    "    if not db:\n",
    "        return do_exit(\"Could not open the database of inserted files -- perhaps it does not exist?\\nSee the log file for more information\", 1)\n",
    "    \n",
    "    event, job_id = window_get_past_job()\n",
    "    \n",
    "    \n",
    "    \n",
    "    if not job_id:\n",
    "        return do_exit(\"no files selected\", 0)\n",
    "    \n",
    "    result = db.search((Query().job_id == job_id) & (Query().failure == None) & (Query().deleted != True))\n",
    "        \n",
    "    delete_list = []\n",
    "    width = 100\n",
    "    \n",
    "    for index, i in enumerate(result):\n",
    "        try:\n",
    "            del_path = Path(i['remote_path'][0])/i['sub_folder']/Path(i['local_path']).name\n",
    "            delete_list.append(del_path)\n",
    "            \n",
    "            result[index].update({'del_path': str(del_path)})\n",
    "            \n",
    "            if len(str(delete_list[-1])) > width:\n",
    "                width = len(str(delete_list[-1])) + 1\n",
    "        except (IndexError, KeyError) as e:\n",
    "            logging.warning(f'error fetching remote_path for deletion: {e}')\n",
    "            continue\n",
    "    \n",
    "    width = 200 if width > 200 else width\n",
    "    \n",
    "    if len(delete_list) < 1:\n",
    "        return do_exit(\"no files to delete\", 0)\n",
    "    \n",
    "    s = multi_line_string()\n",
    "    s.append('DELETE THESE FILES FOREVER?')\n",
    "    s.append('This is very hard to undo!\\n')\n",
    "    [s.append(str(i)) for i in delete_list]\n",
    "            \n",
    "    \n",
    "\n",
    "    proceed = sg.popup_scrolled(s, title='Delete These Files?', \n",
    "                                background_color=\"red\", \n",
    "                                yes_no=True,\n",
    "                                size=(width, 10),\n",
    "                                font=constants.FONT,\n",
    "                                keep_on_top=True)\n",
    "   \n",
    "    \n",
    "    if proceed == \"No\": # take no action and return \"done\"\n",
    "        pass\n",
    "    if proceed == \"Yes\":\n",
    "        errors = []\n",
    "        for index, file in enumerate(result):\n",
    "            del_status = 'unknown error'\n",
    "            path = Path(file['del_path'])\n",
    "            try:\n",
    "                if path.exists():\n",
    "                    if path.is_file():\n",
    "                        del_status = path.unlink()\n",
    "                    elif path.is_dir():\n",
    "                        del_status = shutil.rmtree(path)\n",
    "                    else:\n",
    "                        del_status = 'Unknown file type'\n",
    "                else:\n",
    "                    status = 'File does not exist'\n",
    "            except (FileNotFoundError, OSError) as e:\n",
    "                status = e\n",
    "                            \n",
    "            if del_status != None:\n",
    "                logging.info(f'error encountered while deleting {path}: {del_status}')\n",
    "                file.update({'del_status': del_status})\n",
    "                errors.append(file)\n",
    "            else:\n",
    "                logging.debug(f'deleted: {path}')\n",
    "                file.update({'deleted': True, 'del_status': 'successfully deleted'})\n",
    "            # update the documents\n",
    "            result[index] = file\n",
    "            # update the DB with the results\n",
    "            db.update(file, doc_ids=[file.doc_id])\n",
    "            \n",
    "        deleted = db.search((Query().job_id == job_id) & (Query().deleted == True))\n",
    "        delete_failed = db.search((Query().job_id == job_id) & (Query().deleted == False))\n",
    "\n",
    "        ds = multi_line_string()   \n",
    "\n",
    "        ds.append('*****Deletion Summary*****')\n",
    "        ds.append('The following files were deleted: ')\n",
    "        [ds.append(Path(i['del_path']).name) for i in deleted]\n",
    "        ds.append('\\nThe following files could not be deleted:')\n",
    "        [ds.append(f'{Path(i[\"local_path\"]).name}\\n reason: file does not exist on google drive--{constants.FAILURE_CODES[i[\"failure\"]]}') for i in delete_failed]\n",
    "\n",
    "        print(ds)\n",
    "    \n",
    "    return do_exit('done', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_entry(job_id=None, local_path=None, remote_path=None, sub_folder=None,\n",
    "                student_number=None, failure=None, failure_function=None, inserted_timestamp=None,\n",
    "                del_path=None, deleted=False):\n",
    "    '''build a database entry dictionary with all the required keys'''\n",
    "    \n",
    "    return {'job_id': job_id,\n",
    "            'local_path': local_path,\n",
    "            'remote_path': local_path,\n",
    "            'sub_folder': sub_folder,\n",
    "            'student_number': student_number,\n",
    "            'failure': failure,\n",
    "            'failure_function': failure_function,\n",
    "            'inserted_timestamp': inserted_timestamp,\n",
    "            'del_path': del_path,\n",
    "            'deleted': deleted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_files(files, job_id=0):\n",
    "    '''sort list of Path() file objects in to a \"good\" and \"bad\" set\n",
    "        \"good\" files contain 6 digit substring (likely PowerSchool SIS student number)\n",
    "        \"bad\" not files, contain fewer than 6 digit substring, contain multiple 6 digit substring\n",
    "        \n",
    "    Args:\n",
    "        files(`list`): list of Path() objects\n",
    "    \n",
    "    Returns:\n",
    "        (good_files(`dict`), bad_files(`dict`))\n",
    "    \n",
    "    '''\n",
    "    matches = {}\n",
    "    file_list = []\n",
    "    \n",
    "    for each in files:\n",
    "        if each.is_file() or each.is_dir():\n",
    "#             matches[each] = re.match('^.*?\\D?(\\d{6})\\D+(\\d{6})?.*$', each.name)\n",
    "            matches[each] = re.match('^.*?\\D?(\\d{6}).*$', each.name)\n",
    "        else:\n",
    "#             file_list.append({'job_id': })\n",
    "            file_list.append(table_entry(**{'job_id': job_id, 'failure_function': 'sort_files', \n",
    "                                           'failure': 11, 'local_path': each}))\n",
    "\n",
    "\n",
    "    for key, value in matches.items():\n",
    "        try:\n",
    "            # there should be only one match that appears to be a student number\n",
    "            if value.group(1):\n",
    "                file_list.append(table_entry(**{'job_id': job_id, \n",
    "                              'local_path': key, \n",
    "                              'student_number': value.group(1)}))\n",
    "\n",
    "        except Exception:\n",
    "            file_list.append(table_entry(**{'job_id': job_id,\n",
    "                          'local_path': key,\n",
    "                          'failure': 10, # file contains no student number\n",
    "                          'failure_function': 'sort_files'}))\n",
    "    return(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_dirs(path, depth=2):\n",
    "    '''use system `find` command to cache directory paths into a list\n",
    "    \n",
    "    Args:\n",
    "        path(`str`): path to cache\n",
    "        depth(`int`): depth to search\n",
    "        \n",
    "    Returns:\n",
    "        (`list`, `list`): list of directories, any errors from stdout'''\n",
    "    def byte_to_list(byte): return [l for l in cache.decode('utf-8').split('\\n')]\n",
    "    \n",
    "    command = shlex.split(f'find \"{str(path)}\" -maxdepth {depth} -type d')\n",
    "    process = subprocess.Popen(command, stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "    cache, errors = process.communicate()\n",
    "    \n",
    "    return byte_to_list(cache), byte_to_list(errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_dirs(files, cache):\n",
    "    '''match dictionary of file paths and student id values to directories in cache list\n",
    "    \n",
    "        uses sub-string comparison -- if 'student id' substring is in directory string\n",
    "        add this as a match\n",
    "    \n",
    "    Args:\n",
    "        files(`dict`): dictionary of {Path(): 'Student ID'}\n",
    "        cache(`list`): list of strings\n",
    "    \n",
    "    files items dict keys used here:\n",
    "        [{'student_number': int         # student number (expected)\n",
    "          'remote_path': str            # dest path (updated) with remote paths that contain student_number\n",
    "          }\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "        `dict`: updated files dictionary including key 'remote_path' '''\n",
    "    \n",
    "#     matches = {}\n",
    "#     for file, student_number in files.items():\n",
    "#         matches[file] = [i for i in cache if student_number in i]\n",
    "    update = []\n",
    "    for index, file in enumerate(files):\n",
    "        if file['student_number']:\n",
    "            files[index].update({'remote_path': [i for i in cache if file['student_number'] in i]})\n",
    "        else:\n",
    "            files[index].update({'remote_path': []})\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_summary(file_list):\n",
    "    '''create a summary of actions taken\n",
    "    \n",
    "    summarize files successfully inserted and failures with reasons for failure\n",
    "    \n",
    "    Args:\n",
    "        file_list(`list` of `dict`)\n",
    "        \n",
    "    files item dict keys used here:\n",
    "        [{'local_path': Path()          # src file (expected)\n",
    "          'remote_path': str            # dest path (expected)\n",
    "          'sub_folder': str             # sub folder within remote_path used \n",
    "          'failure': int                # integer code from constants.FAILURE_CODES if copy fails\n",
    "          }\n",
    "        ]\n",
    "    \n",
    "    Returns:\n",
    "        `multi_line_string` object\n",
    "    '''\n",
    "    bad_file = []\n",
    "    multiple_destination = []\n",
    "    copy_failed = []\n",
    "    other = []\n",
    "    inserted = []\n",
    "        \n",
    "    for i in file_list:\n",
    "        if not i['failure']:\n",
    "            inserted.append(i)\n",
    "        else:\n",
    "            if 20 > i['failure'] >= 10 :\n",
    "\n",
    "                bad_file.append(i)\n",
    "            if 30 > i['failure'] >= 20:\n",
    "                copy_failed.append(i)\n",
    "                \n",
    "            if 100 > i['failure'] >= 90:\n",
    "                other.append(i)\n",
    "    \n",
    "\n",
    "    s = multi_line_string()\n",
    "    s.append('******Summary******')\n",
    "    if len(inserted) > 0:\n",
    "        s.append(f'The following files were successfully inserted into student folders:')\n",
    "        [s.append(f\"{i['local_path'].name} ---> {i['remote_path'][0]}/{i['sub_folder']}\\n\") for i in inserted]\n",
    "        \n",
    "    s.append('\\n\\nEach of the files below were skipped and not inserted:')\n",
    "    for each in [bad_file, copy_failed, other]:\n",
    "\n",
    "        \n",
    "        if len(each) > 0:\n",
    "            [s.append(f\"file: {i['local_path'].name}\\n\\treason: {constants.FAILURE_CODES[i['failure']]}\\n\") for i in each]\n",
    "\n",
    "    return s\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_db(file_list):\n",
    "    '''sanitize and write file_list to tinydb database\n",
    "    \n",
    "    values that are not in (str, int, list, float or type(None)) are converted to str representations\n",
    "    \n",
    "    Args:\n",
    "        file_list(`list` of `dict`)\n",
    "        \n",
    "    Returns:\n",
    "        list of records'''\n",
    "    logging.debug(f'writing DB to {constants.DATABASE_PATH}')\n",
    "    ## FIXME -- purge entries older than N weeks\n",
    "    try:\n",
    "        db = TinyDB(constants.DATABASE_PATH)\n",
    "    except (OSError) as e:\n",
    "        logging.error(f'failed to write database {constants.DATABASE_PATH}: {e}')\n",
    "        return False\n",
    "    \n",
    "    cleaned = []\n",
    "    for file in file_list:\n",
    "        temp_item = {}\n",
    "        for key, value in file.items():            \n",
    "            if isinstance(value, (str, int, list, float, type(None))):\n",
    "                temp_item.update({key: value})\n",
    "            else:\n",
    "                temp_item.update({key: str(value)})\n",
    "        cleaned.append(temp_item)\n",
    "    \n",
    "    \n",
    "    doc_ids = db.insert_multiple(cleaned)\n",
    "    return doc_ids\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_files(files, sub_folder):\n",
    "    '''copy list of files into `sub_folder`\n",
    "    \n",
    "    Args:\n",
    "        files(`dict`): dictionary of files\n",
    "        sub_folder(`str`): sub_folder to concatenate to dict item[remote_path]\n",
    "        \n",
    "    files item dict keys used here:\n",
    "        [{'local_path': Path()          # src file (expected)\n",
    "          'remote_path': str            # dest path (expected)\n",
    "          'sub_folder': str             # sub folder within remote_path used (updated)\n",
    "          'failure': int                # integer code from constants.FAILURE_CODES if copy fails (updated as needed)\n",
    "          'failure_function': str       # `insert_files` if copy failes (updated as needed)\n",
    "          'inserted_timestamp': float}  # epoch time copy was executed (updated as needed)\n",
    "         }\n",
    "        ]\n",
    "    Returns:\n",
    "        files(`dict`): updated dictonary of files\n",
    "        '''\n",
    "    func_name = 'insert_files'\n",
    "    for index, file in enumerate(files):\n",
    "        logging.debug(f'processing file: {file[\"local_path\"]}')\n",
    "        \n",
    "        if file['failure']: # skip over failures \n",
    "            continue\n",
    "\n",
    "\n",
    "        if len(file['remote_path']) > 1:\n",
    "            logging.info(constants.FAILURE_CODES[20])\n",
    "            files[index].update({'failure': 20,\n",
    "                                'failure_function': func_name})\n",
    "            continue\n",
    "\n",
    "        if len(file['remote_path']) < 1:\n",
    "            logging.info(constants.FAILURE_CODES[21])\n",
    "            files[index].update({'failure': 21, \n",
    "                                'failure_function': func_name})\n",
    "            continue\n",
    "\n",
    "\n",
    "        if len(file['remote_path']) == 1:\n",
    "            logging.debug(f'copying file to remote path: {file[\"remote_path\"][0]}/{sub_folder}')\n",
    "            result = False\n",
    "            dest = Path(file['remote_path'][0])/sub_folder\n",
    "            try:\n",
    "                src = Path(file['local_path'])\n",
    "            except (TypeError, KeyError) as e:\n",
    "                logging.error(f'error accessing key: \"local_path\" in files dictionary: {e}')\n",
    "                files[index].update({'failure': 90,\n",
    "                                  'failure_function': func_name})\n",
    "                continue\n",
    "\n",
    "            if src.is_dir():\n",
    "                logging.debug(f'source file is directory')\n",
    "                try:\n",
    "                    #### FIXME! -- needs to create and copy into directory\n",
    "                    result = shutil.copytree(src, dest/src.name, dirs_exist_ok=True)\n",
    "                except Exception as e:\n",
    "                    logging.error(f'error copying file: {e}')\n",
    "                    files[index].update({'failure': 22, # exception w\n",
    "                                      'failure_function': func_name})\n",
    "                    continue\n",
    "            else:\n",
    "                logging.debug(f'source file is single file')\n",
    "                try:\n",
    "                    result = shutil.copy(src, dest)\n",
    "                except Exception as e:\n",
    "                    logging.error(f'failed to copy file: \"{file}\": {e}')\n",
    "                    files[index].update({'failure': 23,\n",
    "                                        'failure_function': func_name})\n",
    "\n",
    "        if result:\n",
    "            file['inserted_timestamp'] = time.time()\n",
    "            file['sub_folder'] = sub_folder\n",
    "            files[index].update(file)\n",
    "        else:\n",
    "            logging.error(constants.FAILURE_CODES[23])\n",
    "            files[index].update({'failure': 23,\n",
    "                               'failure_function': func_name})\n",
    "#             failed.append(file)\n",
    "#             failed[-1].update({'failure': 23,\n",
    "#                                'failure_function': func_name})\n",
    "\n",
    "\n",
    "    return files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_program(interactive=False, window=None, update_config=False):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.info('***** run main program *****')\n",
    "    logging.info(f'interactive: {interactive}')\n",
    "    \n",
    "    # rebuild these so the match format of constants.TABLES\n",
    "#     files_inserted = {}\n",
    "#     files_failed = {}\n",
    "#     good_files = {}\n",
    "#     bad_file = {}\n",
    "    file_glob = None\n",
    "    file_list = []\n",
    "    job_id = job_time()\n",
    "    \n",
    "    width = constants.TEXT_WIDTH\n",
    "\n",
    "    \n",
    "    if interactive:\n",
    "        print = wrap_print    \n",
    "    \n",
    "    USER_CONFIG_PATH = Path(constants.USER_CONFIG_PATH)\n",
    "    \n",
    "    logging.debug(f'checking user config: {USER_CONFIG_PATH}')\n",
    "\n",
    "    update_user_config = not(USER_CONFIG_PATH.exists())\n",
    "    \n",
    "    logging.debug(f'user config will be created: {update_user_config}')\n",
    "    \n",
    "    cmd_args_dict = parse_cmdargs()\n",
    "    cfg_files_dict = read_config([constants.DEFAULT_CONFIG_FILE, USER_CONFIG_PATH])\n",
    "    \n",
    "    config = ArgConfigParse.merge_dict(cfg_files_dict, cmd_args_dict)\n",
    "    \n",
    "    logging.debug('processing command line options')    \n",
    "    if config['__cmd_line']['version']:\n",
    "        logging.debug('display version and exit')\n",
    "        return do_exit(version_info, 0)\n",
    "    \n",
    "    if config['__cmd_line']['more_help'] and not interactive:\n",
    "        logging.debug('display help and exit')\n",
    "        print_help()\n",
    "        return do_exit(' ', 0)\n",
    "    \n",
    "    if config['__cmd_line']['update_drive']:\n",
    "        logging.debug('updating user configuration file with new google drive path')\n",
    "        update_user_config = True\n",
    "    \n",
    "    if not config['main']['drive_path']:\n",
    "        if interactive:\n",
    "            logging.debug('prompt user to select shared drive & cum. folder')\n",
    "            print('No Google Shared Drive has been set yet.')\n",
    "            print('Locate the proper Google Shared Drive **and** then the `Student Cumulative Folders (AKA Student Portfolios)` folder')\n",
    "            drive_path_interactive = window_drive_path()\n",
    "            if not drive_path_interactive:\n",
    "                return do_exit('Please choose a Google Shared Drive to proceed', 0)\n",
    "            else:\n",
    "                config['main']['drive_path'] = drive_path_interactive        \n",
    "        if not interactive:\n",
    "            return do_exit(f'Can not run without a Google Shared Drive configured.\\ntry:\\n{sys.argv[0]} -h for help', 1)\n",
    "\n",
    "\n",
    "    \n",
    "    # check that supplied path is indeed a valid cumulative folder path\n",
    "    logging.debug(f\"checking drive path is valid: {config['main']['drive_path']}\")\n",
    "    drive_path = Path(config['main']['drive_path'])\n",
    "    drive_status = check_drive_path(drive_path)\n",
    "    \n",
    "    if window:\n",
    "        window.Refresh()\n",
    "    \n",
    "    if not drive_status[0]:\n",
    "        if interactive:\n",
    "            error = sg.popup_error(wrap_print(f'{drive_path} does not appear to be valid! See the main window for more information.', width), \n",
    "                                       title='Google Drive Error', \n",
    "                                       font=constants.FONT,\n",
    "                                       keep_on_top=True,\n",
    "                                       line_width=constants.TEXT_WIDTH,\n",
    "                                       background_color=\"Red\")\n",
    "\n",
    "        return do_exit(drive_status[1], 0)\n",
    "    \n",
    "    if interactive:\n",
    "        logging.debug('prompt user for files to insert')\n",
    "        print('Select a folder containing student files to insert')\n",
    "        event, file_glob = window_get_dir()\n",
    "    else:\n",
    "        # use command line switch \n",
    "        # file_list = [f for f in Path(path from command line here).glob('*')]\n",
    "        pass\n",
    "    \n",
    "    logging.debug(f'event: {event}, file_list: {file_glob}')        \n",
    "    if file_glob == None or len(file_glob) < 1:\n",
    "        logging.info('no files selected by user')\n",
    "        return do_exit('Cannot proceed without files to insert', 0)\n",
    "\n",
    "    # sort files into those with and without student numbers\n",
    "    logging.debug('sorting files based on filename')\n",
    "    file_list = sort_files(file_glob, job_id.job_id)\n",
    "    \n",
    "    # cache all the student directories \n",
    "    logging.debug(f'caching directories in {drive_path}')\n",
    "    cache, errors = cache_dirs(drive_path)\n",
    "    \n",
    "    # check the cache and bail out with some logging!\n",
    "    logging.error('FIXME! -- need some error catching on cache failures')\n",
    "    \n",
    "    # match files w/ student numbers to directories in the cache\n",
    "    logging.debug('match student ID & files to cached dirs')\n",
    "    file_list = match_dirs(file_list, cache)\n",
    "    \n",
    "    # ask for grade level\n",
    "    logging.debug('prompt for grade level folder')\n",
    "    while True:\n",
    "        event, grade_level = get_grade_level()\n",
    "        \n",
    "        if grade_level:\n",
    "            break\n",
    "            \n",
    "        if event == 'Cancel':\n",
    "            logging.info('user canceled grade level selection')\n",
    "            return do_exit('Processing of files canceled by user', 0)\n",
    "        \n",
    "\n",
    "    logging.debug('confirm chosen grade level folder')\n",
    "    proceed = sg.PopupOKCancel(wrap_print(f'Files will be inserted into the folder: \"{grade_level}\" for each student.\\nThis is difficult to undo!\\n\\nProceed?', supress_print=True), \n",
    "                               title='Proceed?', \n",
    "                               font=constants.FONT,\n",
    "                               keep_on_top=True,\n",
    "                               line_width=constants.TEXT_WIDTH,\n",
    "                               background_color=\"Red\")\n",
    "\n",
    "    \n",
    "    if proceed == 'OK':\n",
    "        file_list = insert_files(file_list, grade_level)\n",
    "    else:\n",
    "        logging.info('user canceled')\n",
    "        return do_exit('Processing of files canceled by user', 0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if update_user_config:\n",
    "        logging.debug('updating user configuration file')\n",
    "        try:\n",
    "            logging.info(f'updating user configuration file: {USER_CONFIG_PATH}')\n",
    "            ArgConfigParse.write(config, USER_CONFIG_PATH, create=True)\n",
    "        except Exception as e:\n",
    "            logging.warning(e)\n",
    "        \n",
    "    records_written = write_db(file_list)\n",
    "    logging.debug(f'database records written: {records_written}')\n",
    "    \n",
    "    s = write_summary(file_list)\n",
    "    \n",
    "    cleaned_records = db_cleanup()\n",
    "    \n",
    "    s.append(f'Expired {len(cleaned_records)} old records from database')\n",
    "    \n",
    "    print(s.string)\n",
    "    if interactive:\n",
    "        window.Refresh()\n",
    "        sg.popup_scrolled(s, title='Summary', font=constants.FONT, size=(int(constants.TEXT_WIDTH*2), None))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return do_exit('done', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    logging.info(f'{constants.APP_NAME} v{constants.VERSION}')\n",
    "    \n",
    "    run_gui = False\n",
    "    if len(sys.argv) <= 1:\n",
    "        run_gui = True\n",
    "    \n",
    "    if '-f' in sys.argv:\n",
    "        logging.debug('likely running in a jupyter environment')\n",
    "        run_gui = True\n",
    "    \n",
    "\n",
    "    if run_gui:\n",
    "        logging.debug('running gui')\n",
    "        TEXT_WIDTH = constants.TEXT_WIDTH\n",
    "        TEXT_ROWS = constants.TEXT_ROWS\n",
    "        FONT_FACE = constants.FONT_FACE\n",
    "        FONT_SIZE = constants.FONT_SIZE\n",
    "        FONT = constants.FONT\n",
    "        \n",
    "        # create a wrapper that matches the text output size\n",
    "        logging.debug('redefining builtin `print` to use `wrap_print`')\n",
    "        print = wrap_print     \n",
    "\n",
    "\n",
    "        def text_fmt(text, *args, **kwargs): return sg.Text(text, *args, **kwargs)\n",
    "        layout = [ [text_fmt(f'{constants.APP_NAME}', font=f'{FONT_FACE} {FONT_SIZE+2}')],\n",
    "                   [text_fmt(f'{constants.URL}', font=f'{FONT_FACE} {FONT_SIZE}')],\n",
    "                   [text_fmt(f'v{constants.VERSION}', font=f'{FONT_FACE} {FONT_SIZE}')],              \n",
    "                   [text_fmt(f'{constants.APP_DESC}', font=f'{FONT_FACE} {FONT_SIZE}')],\n",
    "                   [sg.Output(size=(TEXT_WIDTH+15, TEXT_ROWS), font=FONT)],\n",
    "                   [sg.Button('Insert Files', font=FONT), sg.Button('Remove Files', font=FONT)],\n",
    "                   [sg.Button('Change Shared Drive', font=FONT)],\n",
    "                   [sg.Button('Help', font=FONT), sg.Button('Exit', font=FONT)]\n",
    "                 ]\n",
    "\n",
    "        window = sg.Window(f'{constants.APP_NAME}', layout=layout, keep_on_top=False,\n",
    "                           location=constants.WIN_LOCATION)\n",
    "        \n",
    "        \n",
    "        window.finalize()\n",
    "        window.BringToFront()\n",
    "        \n",
    "        print(f'{constants.APP_NAME} adds files into Student Cumulative Folders stored on Google Drive. Each file or folder full of files must contain a valid PowerSchool Student ID')\n",
    "        print('\\nSelect an action by clicking the buttons below.')\n",
    "        window.Refresh()\n",
    "        \n",
    "\n",
    "        while True:\n",
    "            (event, value) = window.read()\n",
    "\n",
    "            if event == 'Exit' or event == sg.WIN_CLOSED:\n",
    "                break\n",
    "            if event == 'Help':\n",
    "                print_help()\n",
    "            if event == 'Insert Files':\n",
    "                logging.debug(f'sys.argv: {sys.argv}')\n",
    "                ret_val = main_program(interactive=True, window=window)\n",
    "                ret_val()\n",
    "                window.Refresh()\n",
    "            if event == 'Remove Files':\n",
    "                ret_val = delete_files()\n",
    "                ret_val()\n",
    "            if event == 'Change Shared Drive':\n",
    "                drive = window_drive_path()\n",
    "                if drive:\n",
    "                    print('')\n",
    "                    print(f'Changed drive to: {drive}')\n",
    "                    window.Refresh()\n",
    "                    sys.argv.extend(['-g', str(drive)])\n",
    "                    sys.argv.append('-u')                        \n",
    "                logging.debug('run set shared drive here')\n",
    "            \n",
    "        window.close()\n",
    "\n",
    "    else:\n",
    "        ret_val = main_program()\n",
    "        ret_val()\n",
    "    \n",
    "    logging.debug('done')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ =='__main__':\n",
    "    f = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust_handler(handler='Stream', new_level='DEBUG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insertFiles-ca6-NRwd",
   "language": "python",
   "name": "insertfiles-ca6-nrwd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
